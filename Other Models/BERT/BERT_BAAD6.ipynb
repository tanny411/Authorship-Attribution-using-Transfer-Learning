{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from pathlib import Path \n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random \n",
    "\n",
    "# fastai\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "# transformers\n",
    "\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
    "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai version : 1.0.59\n",
      "transformers version : 2.2.1\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "import transformers\n",
    "print('fastai version :', fastai.__version__)\n",
    "print('transformers version :', transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 3) (300, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fe</td>\n",
       "      <td>সাম্প্রদায়িক সংঘাত ও মানবিক প্রতিরোধ সাম্প্রদা...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ij</td>\n",
       "      <td>আজ মাও সেতুং-এর জন্মদিন। মাও সে তুং। বারবার ইত...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mk</td>\n",
       "      <td>গোলাম আযমের বিরুদ্ধে অভিযোগ ৬১ টি, যেকোনো ১ টি...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rn</td>\n",
       "      <td>জলের সন্তরন- (এক) অনেক গুলো সাপ মিজানের শরীরের...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hm</td>\n",
       "      <td>খুবরগুড়ে . . . এইভাবে হতে থাকে ক্রমাগত কেউ মার...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  is_valid\n",
       "0    fe  সাম্প্রদায়িক সংঘাত ও মানবিক প্রতিরোধ সাম্প্রদা...     False\n",
       "1    ij  আজ মাও সেতুং-এর জন্মদিন। মাও সে তুং। বারবার ইত...     False\n",
       "2    mk  গোলাম আযমের বিরুদ্ধে অভিযোগ ৬১ টি, যেকোনো ১ টি...     False\n",
       "3    rn  জলের সন্তরন- (এক) অনেক গুলো সাপ মিজানের শরীরের...     False\n",
       "4    hm  খুবরগুড়ে . . . এইভাবে হতে থাকে ক্রমাগত কেউ মার...     False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_ROOT = Path(\"bro/\")\n",
    "train = pd.read_csv(DATA_ROOT / 'ulm_train.csv')\n",
    "test = pd.read_csv(DATA_ROOT / 'ulm_test.csv')\n",
    "print(train.shape,test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
    "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
    "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
    "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
    "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seed = 42\n",
    "use_fp16 = False\n",
    "bs = 6\n",
    "\n",
    "model_type = 'bert'\n",
    "pretrained_model_name = 'bert-base-multilingual-cased' # 'roberta-base-openai-detector'\n",
    "\n",
    "# model_type = 'bert'\n",
    "# pretrained_model_name='bert-base-uncased'\n",
    "\n",
    "# model_type = 'distilbert'\n",
    "# pretrained_model_name = 'distilbert-base-uncased-distilled-squad'#'distilbert-base-uncased'#'distilbert-base-uncased'\n",
    "\n",
    "#model_type = 'xlm'\n",
    "#pretrained_model_name = 'xlm-clm-enfr-1024'\n",
    "\n",
    "#model_type = 'xlnet'\n",
    "#pretrained_model_name = 'xlnet-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_class.pretrained_model_archive_map.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to set the seed for generating random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersBaseTokenizer(BaseTokenizer):\n",
    "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
    "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
    "        self._pretrained_tokenizer = pretrained_tokenizer\n",
    "        self.max_seq_len = pretrained_tokenizer.max_len\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def __call__(self, *args, **kwargs): \n",
    "        return self\n",
    "\n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        \"\"\"Limits the maximum sequence length and add the special tokens\"\"\"\n",
    "        CLS = self._pretrained_tokenizer.cls_token\n",
    "        SEP = self._pretrained_tokenizer.sep_token\n",
    "        if self.model_type in ['roberta']:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
    "        else:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
    "        return [CLS] + tokens + [SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
    "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer_class.pretrained_vocab_files_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersVocab(Vocab):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
    "        super(TransformersVocab, self).__init__(itos = [])\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        \"Convert a list of tokens `t` to their ids.\"\n",
    "        return self.tokenizer.convert_tokens_to_ids(t)\n",
    "        #return self.tokenizer.encode(t)\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
    "        \"Convert a list of `nums` to their tokens.\"\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
    "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
    "\n",
    "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
    "\n",
    "transformer_processor = [tokenize_processor, numericalize_processor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_first = bool(model_type in ['xlnet'])\n",
    "pad_idx = transformer_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    }
   ],
   "source": [
    "databunch = (TextList.from_df(train, cols='text', processor=transformer_processor)\n",
    "             .split_by_rand_pct(0.1,seed=seed)\n",
    "             .label_from_df(cols= 'label')\n",
    "             .add_test(test)\n",
    "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'okay'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'okay'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check batch and tokenizer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] token : [CLS]\n",
      "[SEP] token : [SEP]\n",
      "[PAD] token : [PAD]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>[CLS] পান ##শা ##লা ০ ##০২ পান ##শা ##লা শ ##ির ##োন ##াম ##ের এক ##টা স ##ির ##িজ ল ##ে ##খা শুরু করে ##ছিল ##াম অনেক আগে । শ ##ি ##ব ##্রাম চ ##ক ##র ##ব ##রত ##ি আ ##মার অনেক মা ##ন ##স ##গ ##ুর ##ু ##দের একজন , তা ##ই পান ##প ##্রে ##মিক কিছু চ ##রি ##ত্র ##ের ম ##ু ##খে P ##UN গ ##ু ##ঁ</td>\n",
       "      <td>hm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] জ ##ঙ্গ ##ি দ ##ম ##নে স ##া ##ফ ##ল ##্য ও [UNK] বাংলাদেশের স ##মা ##জে ##র অ ##ভ ##্য ##ন্ত ##রে জ ##ঙ্গ ##ি ##বাদ যে গ ##ভ ##ীর [UNK] গ ##্রে ##া ##থ ##িত করেছে , তা আ ##জ আর বলা ##র অ ##পে ##ক্ষা র ##া ##খে না । গ ##ত দুই দ ##শ ##ক ধরে আ ##ম ##রা জ ##ঙ্গ ##ি ##বাদ ##ের ব</td>\n",
       "      <td>mk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] জ ##াগ ##্র ##ত প ##্র ##জন ##্ ##ম চ ##ত্ব ##র , চ ##লো চ ##লো , শ ##াহ ##বা ##গ চ ##লো । । র ##ে ##জা ঘ ##ট ##ক শ ##িশ ##ুর ম ##ু ##খে , শ ##াহ ##বা ##গ । [UNK] ম ##ু ##খে , শ ##াহ ##বা ##গ । ব ##োন ##ের ম ##ু ##খে , শ ##াহ ##বা ##গ । [UNK] ম ##ু</td>\n",
       "      <td>rg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] [UNK] ত ##ো ##মার ##ে [UNK] দ ##ে ##খ ##িতে , [UNK] [UNK] [UNK] _ _ _ ( পর ##্ব - চ ##ার ) [UNK] আ ##হ ##মে ##দের ন ##িন ##্দু ##কের ##া বলে ##ন , [UNK] আ ##হ ##মে ##দ হ ##ি ##ম ##ু চ ##রি ##ত্র ##টি স ##ু ##ব ##ো ##ধ ঘ ##ো ##ষে ##র ' শ ##ুন ব ##র ##নার ##ী ' উ ##পন</td>\n",
       "      <td>rn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] [UNK] গ ##ন ##হ ##ত ##্যা _ খ ##ে ##মার র ##ু ##জ শ ##াস ##নের এক [UNK] [UNK] । ছোট ##্ট এই [UNK] খ ##ে ##মার র ##ু ##জ গ ##ের ##িলা ##রা র ##ে ##হ ##াই [UNK] । র ##ু ##জ শ ##ব ##্দ ##টা ফ ##রা ##স ##ী ; অর্থ ল ##াল । কাজ ##েই খ ##ে ##মার র ##ু ##জ শ ##ব ##্দ ##ের অর্থ</td>\n",
       "      <td>ij</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
    "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
    "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
    "databunch.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] [UNK] স ##ং ##ঘ ##াত ও মা ##ন ##বি ##ক প্রতি ##র ##ো ##ধ [UNK] স ##ং ##ঘ ##াত ও মা ##ন ##বি ##ক প্রতি ##র ##ো ##ধ ##ফ ##কি ##র [UNK] = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = আ ##মি যে দেশ ##টি ##তে থ ##াক ##ি এখানে ব ##হ ##ু ##জা ##তি ##ক , ব ##হ ##ু ##ভা ##ষ ##িক মানুষের বা ##স । অনেক ধ ##র্ম ##াব ##ল ##ম ##্ব ##ী , মত ##াব ##ল ##ম ##্ব ##ী মানু ##ষ । ক ##ার ##ো সঙ্গে ক ##ার ##ো কোনো ম ##িল ন ##েই । এর ##া চ ##াই ##লে কিন্তু খুব স ##াম ##ান ##্য [UNK] [UNK] প্রতি ##দিন দ ##া ##ঙ্গ ##া করতে প ##ার ##ত ##ো । না - ত ##ে ##ম ##ন ##টি এখানে হচ্ছে না । হ ##্যা ##ঁ , [UNK] প ##া ##ঠ ##ক - আ ##মি মার্কিন য ##ুক্ত ##রাষ্ট্র ##ের কথা ব ##ল ##ছ ##ি । এটি এমন একটি দেশ , মানু ##ষ মানুষের ব ##ুক ##ের প ##া ##ঁ ##জ ##র [UNK] [UNK] ফ ##েল ##ত ##ো ! য ##দি এ দেশ ##ে ক ##ঠ ##োর আ ##ইন না থ ##াক ##ত ##ো । না - তারা তা প ##ার ##ছে না । প ##ার ##বে না । প ##ার ##বে না এ জন্য , এমন কিছু ক ##র ##লে তাদের ক ##ঠ ##িন শ ##াস ##্তি ##র ম ##ু ##খ ##ো ##ম ##ু ##খ ##ি হতে হবে । তা ##ই এ জ ##ী ##বন ##বা ##জি র ##ে ##খে [UNK] [UNK] [UNK] ক ##র ##বে কে ? প ##াক - ভারত উ ##প ##ম ##হ ##াদ ##েশ জন্ম [UNK] ক ##িং ##বা ব ##ি ##ভ ##ক্ত [UNK] [UNK] [UNK] [UNK] - এর মধ্য [UNK] । ক ##ী ঘটে ##ছিল - তা আ ##মা ##দের ক ##ার ##োর ##ই অ ##জা ##না [UNK] । এ জন্ম ##ই ##তি ##হ ##াস [UNK] জন্ম ##েছে পাকিস্তান - ভারত , পর ##বর্তী ##কালে বাংলাদেশ । একটি ভ ##ূ ##খ ##ণ ##্ড ##ে [UNK] দ ##্ব ##িজ ##াত ##ি ত ##ত ##্ত ##্ব [UNK] , [UNK] শ ##ত্র ##ু স ##ম ##্ ##প ##ত ##্তি আ ##ইন [UNK] করা [UNK] । মানু ##ষে মানু ##ষে ধ ##র্ম ##ের ব ##ি ##ভা ##জন করা [UNK] সে ##ভাবে ##ই খুব পর ##িক ##ল্প ##িত ##ভাবে । ১৯ ##৪ ##৭ সালে ভারত ভ ##াগ ##ের [UNK] অ ##স ##ং ##খ ##্য হ ##িন ##্দু তা ##ঁ ##দের [UNK] [UNK] চলে [UNK] । কারণ জ ##িন ##্ন ##াহ [UNK] র দ ##্ব ##িজ ##াত ##ি ত ##ত ##্ত ##্বে ##র উপর ভ ##িত ##্তি করে [UNK] ও ##ঠ ##া একটি নতুন দেশ ##ে তা ##ঁ ##দের অ ##স্ত ##িত ##্ব র ##ক্ষা করা প ##্র ##শ ##্ন দেখা [UNK] । এর পরে প্রথম ##ে ১৯ ##৫ ##০ এবং তার পর ১৯ ##৬ ##৪ সালে পূর্ব ##ত ##ন পূর্ব পাকিস্তান ##ে [UNK] দ ##া ##ঙ্গ ##ার [SEP]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databunch.train_dl.dl.dataset[0][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check `wordpiece` for non-latin(bangla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check batch and numericalizer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] id : 101\n",
      "[SEP] id : 102\n",
      "[PAD] id : 0\n",
      "Batch shape :  torch.Size([6, 512])\n",
      "tensor([[  101,   938, 37376,  ..., 11737, 66199,   102],\n",
      "        [  101,   958, 11199,  ..., 12079, 53372,   102],\n",
      "        [  101,   100,   978,  ...,   100,   974,   102],\n",
      "        [  101,   948, 12235,  ...,   100,   100,   102],\n",
      "        [  101,   100,   968,  ...,   117,   938,   102],\n",
      "        [  101,   968, 22756,  ..., 26788, 19910,   102]])\n"
     ]
    }
   ],
   "source": [
    "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
    "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
    "print('[PAD] id :', pad_idx)\n",
    "test_one_batch = databunch.one_batch()[0]\n",
    "print('Batch shape : ',test_one_batch.shape)\n",
    "print(test_one_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   101,    938,  37376,  11737,  29261,    974,  26145,  29454,    972,\n",
       "         69514,  30277,  11421,    978,  29806,  74501,  17511, 111238,  11128,\n",
       "        111240, 111228,  15215,    954,  47356,    112,  59136,  11128,  16431,\n",
       "         56251,    112,    168,    976,  19668,  19910,  72614,  27608,    938,\n",
       "         22875, 111240,  39427,  11128,  15215,    100,    970,  45908,  45947,\n",
       "         11421,    937,  11737,  70115,  29740,  12235,  56251,  12235,    920,\n",
       "           920,    938,  24383,  14339,    959,  15691,  28777,  22875,  16431,\n",
       "         28777,  32465,  93915,  45002,  23538,  20699,  21398,  59038,  25017,\n",
       "           100,    973,  16166,  19910,  28410,  24383,  46085, 111240,  39427,\n",
       "         38044,  99475,  13104,    969,  21790,  12079, 111231, 111240,  39427,\n",
       "           969,  15010,  32359,  39994,  79959,    946,  16869,    978,  85040,\n",
       "           968])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numtest = test_one_batch[0][:100]\n",
    "numtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 938, 37376, 11737, 29261, 974, 26145, 29454, 972, 69514]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numtest[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] আমিনুর রহমান মুকুলের স্বল্পদৈর্ঘ্য ছবি'অবরোধ'_ শতাব্দীর আশ্চর্য [UNK] বৃত্তের অনন্ত পরিধি । । আজ থেকে ঠিক একশো এক বছর আগে ১৯১৪ সালের ২৮ জুন [UNK] যুবরাজ আর্চডিউক ফ্রাঞ্চ ফার্ডিন্যান্ড ও তার স্ত্রী প\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"vocab_size\": 119547\n",
    "transformer_tokenizer.decode(numtest.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our model architecture \n",
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, transformer_model: PreTrainedModel):\n",
    "        super(CustomTransformerModel,self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "                \n",
    "        logits = self.transformer(input_ids,\n",
    "                                attention_mask = attention_mask)[0]   \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fe', 'hm', 'ij', 'mk', 'rg', 'rn']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databunch.train_dl.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = len(databunch.train_dl.classes)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 6,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = config_class.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = labels\n",
    "config.use_bfloat16 = use_fp16\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
    "# transformer_model = model_class.from_pretrained(pretrained_model_name, num_labels = 5)\n",
    "\n",
    "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "from transformers import AdamW\n",
    "\n",
    "learner = Learner(databunch, \n",
    "                  custom_transformer_model, \n",
    "                  opt_func = lambda input: AdamW(input,correct_bias=False), \n",
    "                  metrics=[accuracy])\n",
    "\n",
    "# Show graph of learner stats and metrics after each epoch.\n",
    "learner.callbacks.append(ShowGraph(learner))\n",
    "\n",
    "# Put learn in FP16 precision mode. --> Seems to not working\n",
    "if use_fp16: learner = learner.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTransformerModel(\n",
      "  (transformer): BertForSequenceClassification(\n",
      "    (bert): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(learner.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can decide to divide the model in 14 blocks :\n",
    "* 1 Embedding\n",
    "* 12 transformer\n",
    "* 1 classifier\n",
    "\n",
    "(same for bert)\n",
    "In this case, we can split our model in this way :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DistilBERT\n",
    "# list_layers = [learner.model.transformer.distilbert.embeddings,\n",
    "#                learner.model.transformer.distilbert.transformer.layer[0],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[1],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[2],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[3],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[4],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[5],\n",
    "#                learner.model.transformer.pre_classifier]\n",
    "\n",
    "# For bert-base\n",
    "list_layers = [learner.model.transformer.bert.embeddings,\n",
    "              learner.model.transformer.bert.encoder.layer[0],\n",
    "              learner.model.transformer.bert.encoder.layer[1],\n",
    "              learner.model.transformer.bert.encoder.layer[2],\n",
    "              learner.model.transformer.bert.encoder.layer[3],\n",
    "              learner.model.transformer.bert.encoder.layer[4],\n",
    "              learner.model.transformer.bert.encoder.layer[5],\n",
    "              learner.model.transformer.bert.encoder.layer[6],\n",
    "              learner.model.transformer.bert.encoder.layer[7],\n",
    "              learner.model.transformer.bert.encoder.layer[8],\n",
    "              learner.model.transformer.bert.encoder.layer[9],\n",
    "              learner.model.transformer.bert.encoder.layer[10],\n",
    "              learner.model.transformer.bert.encoder.layer[11],\n",
    "              learner.model.transformer.bert.pooler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check groups : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner split in 14 groups\n",
      "[Sequential(\n",
      "  (0): Embedding(119547, 768, padding_idx=0)\n",
      "  (1): Embedding(512, 768)\n",
      "  (2): Embedding(2, 768)\n",
      "  (3): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (4): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Dropout(p=0.1, inplace=False)\n",
      "  (3): Linear(in_features=768, out_features=6, bias=True)\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "learner.split(list_layers)\n",
    "num_groups = len(learner.layer_groups)\n",
    "print('Learner split in',num_groups,'groups')\n",
    "print(learner.layer_groups)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "Now we can finally use all the fastai build-in features to train our model. Like the ULMFiT method, we will use **Slanted Triangular Learning Rates**, **Discriminate Learning Rate** and **gradually unfreeze the model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('untrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('untrain');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we first freeze all the groups but the classifier with :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check which layer are trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTransformerModel\n",
       "======================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "======================================================================\n",
       "Embedding            [512, 768]           91,812,096 False     \n",
       "______________________________________________________________________\n",
       "Embedding            [512, 768]           393,216    False     \n",
       "______________________________________________________________________\n",
       "Embedding            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [768]                590,592    True      \n",
       "______________________________________________________________________\n",
       "Tanh                 [768]                0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [768]                0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [6]                  4,614      True      \n",
       "______________________________________________________________________\n",
       "\n",
       "Total params: 177,858,054\n",
       "Total trainable params: 595,206\n",
       "Total non-trainable params: 177,262,848\n",
       "Optimized with fd484911bf8\n",
       "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
       "Loss function : FlattenedLoss\n",
       "======================================================================\n",
       "Callbacks functions applied \n",
       "    ShowGraph"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **Slanted Triangular Learning Rates** you have to use the function ``one_cycle``. For more information please check the fastai documentation [here](https://docs.fast.ai/callbacks.one_cycle.html). \n",
    "\n",
    "To use our ``one_cycle`` we will need an optimum learning rate. We can find this learning rate by using a learning rate finder which can be called by using ``lr_find``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         8.440509    #na#        00:10     \n",
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min numerical gradient: 8.32E-04\n",
      "Min loss divided by 10: 4.37E-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student_1/.local/lib/python3.6/site-packages/fastai/sixel.py:16: UserWarning: You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel\n",
      "  warn(\"You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.recorder.plot(skip_end=7,suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min numerical gradient: 8.32E-04\n",
      "Min loss divided by 10: 4.37E-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student_1/.local/lib/python3.6/site-packages/fastai/sixel.py:16: UserWarning: You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel\n",
      "  warn(\"You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.recorder.plot(skip_end=14,suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008317637711026709"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = learner.recorder.min_grad_lr\n",
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will pick a value a bit before the minimum, where the loss still improves.\n",
    "Next we will use ``fit_one_cycle`` with the chosen learning rate as the maximum learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         1.440972    1.213701    0.566667  00:39     \n",
      "1         1.321238    1.096493    0.538889  00:39     \n",
      "2         1.052915    1.027263    0.572222  00:39     \n",
      "3         0.800315    0.763710    0.716667  00:39     \n",
      "4         0.738587    0.670436    0.761111  00:39     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(5,max_lr=lr,moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('fifth_cycle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets see how far pretrained multilingual bert can go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.fit_one_cycle(10,max_lr=1e-03,moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.fit_one_cycle(10,max_lr=1e-03,moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Looks like oscillation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('fifth_cycle');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then unfreeze the second group of layers and repeat the operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         2.076243    #na#        00:09     \n",
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 1.58E-06\n",
      "Min loss divided by 10: 4.37E-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student_1/.local/lib/python3.6/site-packages/fastai/sixel.py:16: UserWarning: You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel\n",
      "  warn(\"You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot(skip_end=7,suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5848931924611132e-06"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = learner.recorder.min_grad_lr\n",
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that we use slice to create separate learning rate for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         0.717063    0.649820    0.777778  00:44     \n",
      "1         0.653574    0.632761    0.783333  00:44     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(2, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('seventh_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('seventh_cycle');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.freeze_to(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         0.654547    0.560868    0.811111  00:49     \n",
      "1         0.565911    0.524572    0.811111  00:49     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(2, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('nineth_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('nineth_cycle');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we unfreeze all the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         0.464625    0.432993    0.816667  01:51     \n",
      "1         0.350756    0.335737    0.872222  01:51     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(2, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('eleventh_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         0.248207    0.362638    0.844444  01:48     \n",
      "1         0.324291    0.309610    0.883333  01:48     \n",
      "2         0.236128    0.282102    0.888889  01:48     \n",
      "3         0.163207    0.265682    0.888889  01:48     \n",
      "4         0.144963    0.237124    0.894444  01:48     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(5, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))\n",
    "learner.save('16th_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         0.127669    0.251709    0.888889  01:48     \n",
      "1         0.146631    0.207671    0.922222  01:48     \n",
      "2         0.120595    0.225826    0.922222  01:48     \n",
      "3         0.073617    0.197451    0.922222  01:49     \n",
      "4         0.075474    0.203804    0.927778  01:48     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(5, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))\n",
    "learner.save('21st_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         0.076217    0.203757    0.911111  01:47     \n",
      "1         0.099439    0.191921    0.922222  01:48     \n",
      "2         0.060514    0.224196    0.916667  01:48     \n",
      "3         0.038200    0.184359    0.944444  01:48     \n",
      "4         0.035232    0.176545    0.944444  01:48     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(5, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))\n",
    "learner.save('26th_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         0.048777    0.168789    0.950000  01:48     \n",
      "1         0.041498    0.182499    0.955556  01:48     \n",
      "2         0.045916    0.182129    0.955556  01:48     \n",
      "3         0.028575    0.182004    0.955556  01:48     \n",
      "4         0.029860    0.181737    0.955556  01:48     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(5, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))\n",
    "learner.save('30th_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         0.040757    0.199297    0.927778  01:49     \n",
      "1         0.024647    0.174629    0.950000  01:48     \n",
      "2         0.018106    0.169789    0.950000  01:48     \n",
      "3         0.011312    0.172013    0.950000  01:48     \n",
      "4         0.012961    0.183215    0.950000  01:48     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(5, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))\n",
    "learner.save('35th_cycle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating prediction\n",
    "Now that the model is trained, we want to generate predictions from the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(df):\n",
    "    text_array = df[\"text\"].tolist()\n",
    "    print(len(text_array))\n",
    "\n",
    "    final_preds = []\n",
    "\n",
    "    for text in text_array:\n",
    "      preds = learner.predict(text)\n",
    "      final_preds.append(str(preds[0]))\n",
    "\n",
    "    targets = df[\"label\"].tolist()\n",
    "\n",
    "    err=[]\n",
    "    count =0;\n",
    "    tst = len(text_array)\n",
    "\n",
    "    for i in range(tst):\n",
    "        if(targets[i]==final_preds[i]):\n",
    "          count = count+1\n",
    "        else:\n",
    "          err.append((targets[i],final_preds[i]))\n",
    "    print(\"Accuracy: \")\n",
    "    print(count/tst)\n",
    "    print(err)\n",
    "\n",
    "    return final_preds,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "Accuracy: \n",
      "0.9333333333333333\n",
      "[('ij', 'rn'), ('rg', 'rn'), ('rn', 'mk'), ('ij', 'rn'), ('mk', 'rn'), ('mk', 'rg'), ('rg', 'ij'), ('ij', 'rg'), ('hm', 'mk'), ('ij', 'rn'), ('mk', 'rg'), ('mk', 'rg'), ('mk', 'hm'), ('fe', 'rn'), ('ij', 'rn'), ('mk', 'rg'), ('hm', 'mk'), ('rg', 'mk'), ('rn', 'mk'), ('rn', 'rg')]\n"
     ]
    }
   ],
   "source": [
    "pred,targ = testing(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This NoteBook combines the ``transformers`` library with ``fastai`` library. It allows us to use **Slanted Triangular Learning Rates**, **Discriminate Learning Rate** and even **Gradual Unfreezing**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* Hugging Face, Transformers GitHub (Nov 2019), [https://github.com/huggingface/transformers](https://github.com/huggingface/transformers)\n",
    "* Fast.ai, Fastai documentation (Nov 2019), [https://docs.fast.ai/text.html](https://docs.fast.ai/text.html)\n",
    "* Jeremy Howard & Sebastian Ruder, Universal Language Model Fine-tuning for Text Classification (May 2018), [https://arxiv.org/abs/1801.06146](https://arxiv.org/abs/1801.06146)\n",
    "* Keita Kurita's article : [A Tutorial to Fine-Tuning BERT with Fast AI](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/) (May 2019)\n",
    "* Dev Sharma's article : [Using RoBERTa with Fastai for NLP](https://medium.com/analytics-vidhya/using-roberta-with-fastai-for-nlp-7ed3fed21f6c) (Sep 2019)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
