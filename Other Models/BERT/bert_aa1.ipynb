{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from pathlib import Path \n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random \n",
    "\n",
    "# fastai\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "# transformers\n",
    "\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
    "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai version : 1.0.59\n",
      "transformers version : 2.2.1\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "import transformers\n",
    "print('fastai version :', fastai.__version__)\n",
    "print('transformers version :', transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full.csv  OurDataset_test.csv  OurDataset_train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls we"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14374, 3) (3592, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shunil_gongopaddhay</td>\n",
       "      <td>থেকে কত দূরে চলে এসেছে ভরত। সে হেসে উঠল আপন মন...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>humayun_ahmed</td>\n",
       "      <td>এতে ভয় কমে যায়। বল একটা গল্প।’ ‘তুমি বল।’ আনিস...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shomresh</td>\n",
       "      <td>হবে। ওই দেখুন ওর এক চোখ কানা। ডান দিকটা দিয়ে দ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>humayun_ahmed</td>\n",
       "      <td>বললাম, আপনি ওর গায়ে হাত দিলেন কেন? ষণ্ডাগণ্ডা ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>humayun_ahmed</td>\n",
       "      <td>হত! আবার চাদর মুড়ি দিয়ে নিজেকে গুটিয়ে ফেলি। যে...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label                                               text  \\\n",
       "0  shunil_gongopaddhay  থেকে কত দূরে চলে এসেছে ভরত। সে হেসে উঠল আপন মন...   \n",
       "1        humayun_ahmed  এতে ভয় কমে যায়। বল একটা গল্প।’ ‘তুমি বল।’ আনিস...   \n",
       "2             shomresh  হবে। ওই দেখুন ওর এক চোখ কানা। ডান দিকটা দিয়ে দ...   \n",
       "3        humayun_ahmed  বললাম, আপনি ওর গায়ে হাত দিলেন কেন? ষণ্ডাগণ্ডা ...   \n",
       "4        humayun_ahmed  হত! আবার চাদর মুড়ি দিয়ে নিজেকে গুটিয়ে ফেলি। যে...   \n",
       "\n",
       "   is_valid  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_ROOT = Path(\"we/\")\n",
    "train = pd.read_csv(DATA_ROOT / 'OurDataset_train.csv')\n",
    "test = pd.read_csv(DATA_ROOT / 'OurDataset_test.csv')\n",
    "print(train.shape,test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
    "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
    "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
    "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
    "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seed = 42\n",
    "use_fp16 = False\n",
    "bs = 6\n",
    "\n",
    "model_type = 'bert'\n",
    "pretrained_model_name = 'bert-base-multilingual-cased' # 'roberta-base-openai-detector'\n",
    "\n",
    "# model_type = 'bert'\n",
    "# pretrained_model_name='bert-base-uncased'\n",
    "\n",
    "# model_type = 'distilbert'\n",
    "# pretrained_model_name = 'distilbert-base-uncased-distilled-squad'#'distilbert-base-uncased'#'distilbert-base-uncased'\n",
    "\n",
    "#model_type = 'xlm'\n",
    "#pretrained_model_name = 'xlm-clm-enfr-1024'\n",
    "\n",
    "#model_type = 'xlnet'\n",
    "#pretrained_model_name = 'xlnet-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_class.pretrained_model_archive_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersBaseTokenizer(BaseTokenizer):\n",
    "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
    "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
    "        self._pretrained_tokenizer = pretrained_tokenizer\n",
    "        self.max_seq_len = pretrained_tokenizer.max_len\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def __call__(self, *args, **kwargs): \n",
    "        return self\n",
    "\n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        \"\"\"Limits the maximum sequence length and add the special tokens\"\"\"\n",
    "        CLS = self._pretrained_tokenizer.cls_token\n",
    "        SEP = self._pretrained_tokenizer.sep_token\n",
    "        if self.model_type in ['roberta']:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
    "        else:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
    "        return [CLS] + tokens + [SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
    "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer_class.pretrained_vocab_files_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersVocab(Vocab):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
    "        super(TransformersVocab, self).__init__(itos = [])\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        \"Convert a list of tokens `t` to their ids.\"\n",
    "        return self.tokenizer.convert_tokens_to_ids(t)\n",
    "        #return self.tokenizer.encode(t)\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
    "        \"Convert a list of `nums` to their tokens.\"\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
    "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
    "\n",
    "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
    "\n",
    "transformer_processor = [tokenize_processor, numericalize_processor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_first = bool(model_type in ['xlnet'])\n",
    "pad_idx = transformer_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    }
   ],
   "source": [
    "databunch = (TextList.from_df(train, cols='text', processor=transformer_processor)\n",
    "             .split_by_rand_pct(0.1,seed=seed)\n",
    "             .label_from_df(cols= 'label')\n",
    "             .add_test(test)\n",
    "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] token : [CLS]\n",
      "[SEP] token : [SEP]\n",
      "[PAD] token : [PAD]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>[CLS] ক ##লক ##ার ##খা ##না ? আরও য ##ন্ত ##্র - ন ##ির ##্ ##ভ ##রত ##া ? আরও আর ##াম - [UNK] ? অ ##গ ##্র ##গ ##ম ##ন মা ##নে ক ##ি স ##ম ##কা ##মি ##তা আর ব ##ি ##বা ##হ ব ##র ##্জ ##ন ? অ ##গ ##্র ##গ ##ম ##ন ক ##ি মানু ##ষক ##ে বা ##ঁ ##চ ##তে [UNK] ? অ ##ন ##ু</td>\n",
       "      <td>shirshendu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] গ ##ল্প প ##া ##ঠ ##াল ##ে যে ##হ ##ে ##ত ##ু আ ##মি গ ##ল্প ল ##ে ##খ ##ক বলে পরিচিত ন ##ই , আ ##মার গ ##ল্প [UNK] ঠ ##ো ##ঙ ##ার মত ক ##ু ##ঁ ##চ ##কে ফ ##েলে [UNK] [UNK] হ ##াব ##িজ ##ি ##বি ক ##াগ ##জে ##র [UNK] । এর ##শা ##দ ##কে ক ##্ ##ষ ##ম ##তা ##চ ##্য ##ূ ##ত করতে</td>\n",
       "      <td>toslima_nasrin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] আবার চ ##ল ##তে শুরু ক ##র ##বে । এক প ##থ থেকে আর ##েক প ##থ । অন্য প ##থ ##ের ম ##ো ##ড়ে । [UNK] আ ##হ ##ম ##দ হ ##ো ##সে ##ন তখন ##ো ক ##া ##ঁ ##দ ##ছে । [UNK] দ ##াম [UNK] [UNK] কিছু ##ক্ষণ পরে বা ##ই ##রে [UNK] এ ##লো শ ##ও ##ক ##ত । ল ##ম ##্ব ##া দ ##ে ##হ</td>\n",
       "      <td>zahir_rayhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] [UNK] স ##ি ##গ ##ারে ##ট খা ##চ ##্ ##ছে , প্রকাশ ##্যে ##ই । ধ ##্র ##ু ##ব য ##ত ##দ ##ূ ##র জ ##ানে , [UNK] স ##ি ##গ ##ারে ##ট [UNK] না । এ ##খ ##ন খা ##চ ##্ ##ছে স ##ম ##্ ##ভ ##ব ##ত ভ ##িত ##র ##কার উ ##দ ##্বে ##গ - উ ##ৎ ##ক ##ণ ##্ ##ঠ ##াক ##ে স ##াম ##াল</td>\n",
       "      <td>shirshendu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] ক ##ি ক ##র ##বে মনে ক ##র ? ক ##ি আ ##মা ##কে আ ##পন ##ি করতে বলে ##ন ? ত ##ো ##মা ##কে ? [UNK] জ ##ী ##বা ##ন ##ন্দ স ##্ত ##ব ##্ধ ন ##তম ##ু ##খে [UNK] ত ##ৈ ##ল ##বি ##র ##ল প ##্র ##দ ##ী ##পের বা ##তি ##টা অ ##কার ##ণ ##ে শ ##ু ##ধ ##ু শ ##ু ##ধ ##ু কে ##বল</td>\n",
       "      <td>shorotchandra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
    "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
    "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
    "databunch.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] থেকে ক ##ত দ ##ূ ##রে চলে এ ##সে ##ছে ভ ##রত । সে হ ##েস ##ে উ ##ঠ ##ল আ ##পন মনে । বা ##লিক ##া ব ##ধ ##ূ ##টি ##কে কোন স্কুল ##ে প ##া ##ঠ ##ান ##ো হবে , তা ##ই [UNK] স ##র ##লা ও ব ##ি ##বি ##র মধ্যে ট ##ানা ##টা ##নি শুরু [UNK] গ ##েল । স ##র ##লা [UNK] ব ##ে ##থ ##ুন স্কুল ##ে , ব ##ি ##বি ল ##োর ##েট ##া হ ##া ##উ ##জে । দ ##ু [UNK] জন ##ের ##ই ধ ##ারণ ##া , যার যার ন ##িজের স্কুল ##টি ##ই বেশি ভ ##াল ##ো । ব ##ে ##থ ##ুন স্কুল বা ##ঙ ##াল ##ি [UNK] বাংলা - মা ##ধ ##্য ##ম , আর ল ##োর ##েট ##ো হ ##া ##উ ##জ স ##াহ ##ে ##ব প ##াড়া ##র ইংরেজি স্কুল , সেখানে বা ##ঙ ##াল ##ি ছ ##াত ##্রী ##র [UNK] ফ ##ির ##ি ##ঙ্গ ##ি ছ ##াত ##্রী ##ই বেশি । ব ##ে ##থ ##ুন ##ের অনেক ছ ##াত ##্রী এ ##খ ##ন স ##মা ##জে ##র নাম - করা ম ##হ ##িলা । এই ত ##ো গ ##ত বছর ##েই ব ##ে ##থ ##ুন ##ের একটি ছ ##াত ##্রী ##কে [UNK] হ ##ই ##চ ##ই [UNK] [UNK] । প ##্র ##বেশ ##িকা [UNK] ভ ##াল ##ো ##ভাবে উ ##ত ##্ত ##ীর ##্ণ [UNK] অব ##লা দ ##াস নামে [UNK] ঠ ##িক করে ##ছিল ড ##াক ##্তা ##রি [UNK] । কিন্তু কলকাতা মে ##ড ##িক ##েল কলেজ ##ে ছ ##াত ##্রী ##দের [UNK] [UNK] না । কিন্তু অব ##লার দ ##াব ##ি , কে ##নো সে ড ##াক ##্তা ##রি [UNK] প ##ার ##বে না ? শেষ পর্যন্ত তাকে [UNK] [UNK] হলো মা ##দ ##্র ##াজ ##ের মে ##ড ##িক ##েল কলেজ ##ে । অব ##লার জ ##ে ##দ দ ##ে ##খে বা ##ঙ ##লা সরকার তার জন্য [UNK] ট ##াকা ##র মা ##সি ##ক ব ##ৃত ##্তি ##র ##ও অ ##ন ##ু ##ম ##ো ##দ ##ন করেছে । দেশের [UNK] ক ##ি আ ##ন্দ ##ে ##াল ##ন [UNK] , ব ##ে ##থ ##ুন কলেজ ##ে তার প ##্র ##ভা ##ব [UNK] । ই ##ল ##বার ##্ট ব ##িল ##ের [UNK] স ##াহ ##ে ##ব ##রা যখন এ [UNK] মানু ##ষ ##দের ব ##ি ##দ ##্যে - ব ##ু ##দ্ধ ##ি [UNK] যা - তা করা প ##্র ##চার করতে ল ##াগ ##ল , তখন ক ##াম ##িন ##ী সে ##ন নামে একটি ত ##ে ##জ ##স ##্ব ##িন ##ী ছ ##াত ##্রী ##র ন ##ে ##ত ##ৃত ##্বে ব ##ে ##থ ##ুন ##ের [UNK] ব ##িক ##্ ##ষে ##া ##ভ [UNK] । স ##ুর ##েন [UNK] যে ##দিন জ ##েল হল , সে ##দিন ব ##ে ##থ ##ুন ##ের সব ছ ##াত ##্রী হ ##াতে ক ##াল ##ো ফ ##িতে ব ##ে ##ধ ##ে এ ##সে ##ছিল স্কুল ##ে । ল ##ে ##ারে ##টে ##া হ ##া ##উ ##জে এ ##সব কিছু ##ই [UNK] না । সেখানে [UNK] ন ##ি ##ষ ##ি ##দ্ধ । প ##্র ##ভ ##ু য ##িশ ##ুর [UNK] করে [UNK] প [SEP]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databunch.train_dl.dl.dataset[0][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] id : 101\n",
      "[SEP] id : 102\n",
      "[PAD] id : 0\n",
      "Batch shape :  torch.Size([6, 512])\n",
      "tensor([[  101,   948, 12079,  ..., 22875, 33664,   102],\n",
      "        [  101,   938, 55077,  ..., 39893, 38044,   102],\n",
      "        [  101,   100,   969,  ...,   970, 15691,   102],\n",
      "        [  101, 16869, 53512,  ..., 15215,   920,   102],\n",
      "        [  101, 18601,   136,  ..., 51003, 71243,   102],\n",
      "        [  101,   979, 27608,  ...,   970, 69514,   102]])\n"
     ]
    }
   ],
   "source": [
    "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
    "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
    "print('[PAD] id :', pad_idx)\n",
    "test_one_batch = databunch.one_batch()[0]\n",
    "print('Batch shape : ',test_one_batch.shape)\n",
    "print(test_one_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   101,    948,  12079,  89362,  18243,    965,  11199,  42651,  53574,\n",
       "         12235,  26109,    920,    938,  55631,  16755,    974,  16166,  15002,\n",
       "         36715,  82925,    100,    100, 100024,    100,    100,  28777,  22875,\n",
       "         39002,    954,  67735,    118,    100,    944,  29993,    970,  29993,\n",
       "         32294,    920,    937, 111229,  66946,  37289, 111240,  82445,  14176,\n",
       "         40433,  36715,    948,  27608,  13104,  15002,  53761,  58417,    100,\n",
       "           938,  55077,  41431,    966,  93168,  12079,    967,  59712,    117,\n",
       "         52038,  14998,    966, 111238,  11128,  15215, 100840,    970,  29993,\n",
       "           938,  53574,  12235,    920,  14770,  13104,  15002,    100,    951,\n",
       "         67366,  12079,    100,  12051,  22904,    978,  65383,    948, 111240,\n",
       "         29621,  15258,    974,  16166,  72703,    976,  15691, 111240, 103598,\n",
       "         11421])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numtest = test_one_batch[0][:100]\n",
    "numtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 948, 12079, 89362, 18243, 965, 11199, 42651, 53574, 12235]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numtest[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] কাউকে দেখছি না । আমাদের রুমটা বেশ [UNK] [UNK] সব [UNK] [UNK] একশ জন ছেলে - [UNK] এসে বসেছে । অঙ্ক কম্পিটিশনটা কীরকম হবে সে [UNK] আমার কোন ধারণা নেই, তাই ধৈর্য ধরে বসে আছি । এরকম [UNK] ঘন্টা [UNK] এবং সাথে সাতে ক্লাস রুমের শিক্ষকের'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"vocab_size\": 119547\n",
    "transformer_tokenizer.decode(numtest.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our model architecture \n",
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, transformer_model: PreTrainedModel):\n",
    "        super(CustomTransformerModel,self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "                \n",
    "        logits = self.transformer(input_ids,\n",
    "                                attention_mask = attention_mask)[0]   \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MZI',\n",
       " 'bongkim',\n",
       " 'humayun_ahmed',\n",
       " 'manik_bandhopaddhay',\n",
       " 'nazrul',\n",
       " 'nihar_ronjon_gupta',\n",
       " 'robindronath',\n",
       " 'shirshendu',\n",
       " 'shomresh',\n",
       " 'shordindu',\n",
       " 'shorotchandra',\n",
       " 'shottojit_roy',\n",
       " 'shunil_gongopaddhay',\n",
       " 'tarashonkor',\n",
       " 'toslima_nasrin',\n",
       " 'zahir_rayhan']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databunch.train_dl.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = len(databunch.train_dl.classes)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 16,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = config_class.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = labels\n",
    "config.use_bfloat16 = use_fp16\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
    "# transformer_model = model_class.from_pretrained(pretrained_model_name, num_labels = 5)\n",
    "\n",
    "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "from transformers import AdamW\n",
    "\n",
    "learner = Learner(databunch, \n",
    "                  custom_transformer_model, \n",
    "                  opt_func = lambda input: AdamW(input,correct_bias=False), \n",
    "                  metrics=[accuracy])\n",
    "\n",
    "# Show graph of learner stats and metrics after each epoch.\n",
    "learner.callbacks.append(ShowGraph(learner))\n",
    "\n",
    "# Put learn in FP16 precision mode. --> Seems to not working\n",
    "if use_fp16: learner = learner.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTransformerModel(\n",
      "  (transformer): BertForSequenceClassification(\n",
      "    (bert): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (classifier): Linear(in_features=768, out_features=16, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(learner.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can decide to divide the model in 14 blocks :\n",
    "* 1 Embedding\n",
    "* 12 transformer\n",
    "* 1 classifier\n",
    "\n",
    "(same for bert)\n",
    "In this case, we can split our model in this way :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DistilBERT\n",
    "# list_layers = [learner.model.transformer.distilbert.embeddings,\n",
    "#                learner.model.transformer.distilbert.transformer.layer[0],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[1],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[2],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[3],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[4],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[5],\n",
    "#                learner.model.transformer.pre_classifier]\n",
    "\n",
    "# For bert-base\n",
    "list_layers = [learner.model.transformer.bert.embeddings,\n",
    "              learner.model.transformer.bert.encoder.layer[0],\n",
    "              learner.model.transformer.bert.encoder.layer[1],\n",
    "              learner.model.transformer.bert.encoder.layer[2],\n",
    "              learner.model.transformer.bert.encoder.layer[3],\n",
    "              learner.model.transformer.bert.encoder.layer[4],\n",
    "              learner.model.transformer.bert.encoder.layer[5],\n",
    "              learner.model.transformer.bert.encoder.layer[6],\n",
    "              learner.model.transformer.bert.encoder.layer[7],\n",
    "              learner.model.transformer.bert.encoder.layer[8],\n",
    "              learner.model.transformer.bert.encoder.layer[9],\n",
    "              learner.model.transformer.bert.encoder.layer[10],\n",
    "              learner.model.transformer.bert.encoder.layer[11],\n",
    "              learner.model.transformer.bert.pooler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check groups : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner split in 14 groups\n",
      "[Sequential(\n",
      "  (0): Embedding(119547, 768, padding_idx=0)\n",
      "  (1): Embedding(512, 768)\n",
      "  (2): Embedding(2, 768)\n",
      "  (3): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (4): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Dropout(p=0.1, inplace=False)\n",
      "  (3): Linear(in_features=768, out_features=16, bias=True)\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "learner.split(list_layers)\n",
    "num_groups = len(learner.layer_groups)\n",
    "print('Learner split in',num_groups,'groups')\n",
    "print(learner.layer_groups)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "Now we can finally use all the fastai build-in features to train our model. Like the ULMFiT method, we will use **Slanted Triangular Learning Rates**, **Discriminate Learning Rate** and **gradually unfreeze the model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir models/aa1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('aa1/untrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('aa1/untrain');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we first freeze all the groups but the classifier with :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check which layer are trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTransformerModel\n",
       "======================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "======================================================================\n",
       "Embedding            [512, 768]           91,812,096 False     \n",
       "______________________________________________________________________\n",
       "Embedding            [512, 768]           393,216    False     \n",
       "______________________________________________________________________\n",
       "Embedding            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [768]                590,592    True      \n",
       "______________________________________________________________________\n",
       "Tanh                 [768]                0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [768]                0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [16]                 12,304     True      \n",
       "______________________________________________________________________\n",
       "\n",
       "Total params: 177,865,744\n",
       "Total trainable params: 602,896\n",
       "Total non-trainable params: 177,262,848\n",
       "Optimized with f4205a7c268\n",
       "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
       "Loss function : FlattenedLoss\n",
       "======================================================================\n",
       "Callbacks functions applied \n",
       "    ShowGraph"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         11.157290   #na#        00:13     \n",
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min numerical gradient: 4.79E-04\n",
      "Min loss divided by 10: 1.58E-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student_1/.local/lib/python3.6/site-packages/fastai/sixel.py:16: UserWarning: You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel\n",
      "  warn(\"You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.recorder.plot(skip_end=7,suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min numerical gradient: 4.79E-04\n",
      "Min loss divided by 10: 1.58E-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student_1/.local/lib/python3.6/site-packages/fastai/sixel.py:16: UserWarning: You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel\n",
      "  warn(\"You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.recorder.plot(skip_end=14,suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004786300923226385"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = learner.recorder.min_grad_lr\n",
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will pick a value a bit before the minimum, where the loss still improves.\n",
    "Next we will use ``fit_one_cycle`` with the chosen learning rate as the maximum learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         1.869246    1.872541    0.382046  05:09     \n",
      "1         1.510628    1.409339    0.534447  05:10     \n",
      "2         1.279805    1.372429    0.569937  05:09     \n",
      "3         1.340494    1.172648    0.611691  05:09     \n",
      "4         1.139867    1.176096    0.610995  05:10     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(5,max_lr=lr,moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('aa1/fifth_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         1.694818    #na#        00:10     \n",
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 9.12E-07\n",
      "Min loss divided by 10: 2.29E-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student_1/.local/lib/python3.6/site-packages/fastai/sixel.py:16: UserWarning: You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel\n",
      "  warn(\"You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot(skip_end=7,suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.120108393559096e-07"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = learner.recorder.min_grad_lr\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         1.074048    1.125918    0.636047  05:44     \n",
      "1         1.102653    1.103620    0.638135  05:45     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(2, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('aa1/seventh_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('aa1/seventh_cycle');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.freeze_to(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         0.982462    1.071483    0.661099  06:28     \n",
      "1         0.989750    1.026098    0.683368  06:27     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(2, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('aa1/nineth_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('aa1/nineth_cycle');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         0.691139    0.924466    0.705637  14:26     \n",
      "1         0.607819    0.765149    0.755045  14:26     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(2, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('aa1/eleventh_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('aa1/eleventh_cycle');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         0.524925    0.793026    0.750870  14:22     \n",
      "1         0.518122    0.587573    0.813500  14:24     \n",
      "2         0.503640    0.529490    0.834377  14:25     \n",
      "3         0.348622    0.474804    0.855950  14:26     \n",
      "4         0.309198    0.488710    0.853862  14:28     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(5, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))\n",
    "learner.save('aa1/16th_cycle') ##78--85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         0.464793    0.523459    0.840640  14:26     \n",
      "1         0.290775    0.507660    0.840640  14:25     \n",
      "2         0.221737    0.391621    0.884482  14:25     \n",
      "3         0.235609    0.395680    0.878914  14:25     \n",
      "4         0.220904    0.367843    0.887265  14:25     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(5, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))\n",
    "learner.save('aa1/21st_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         0.218173    0.437637    0.862909  14:25     \n",
      "1         0.241426    0.399211    0.879610  14:26     \n",
      "2         0.170548    0.311558    0.908142  14:26     \n",
      "3         0.141434    0.314918    0.903967  14:27     \n",
      "4         0.160381    0.297051    0.908142  14:27     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(5, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))\n",
    "learner.save('aa1/26th_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         0.125065    0.304410    0.910926  14:26     \n",
      "1         0.134035    0.329924    0.905358  14:26     \n",
      "2         0.083073    0.264938    0.917884  14:27     \n",
      "3         0.080816    0.281153    0.913709  14:27     \n",
      "4         0.108152    0.259635    0.915101  14:27     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(5, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))\n",
    "learner.save('aa1/30th_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         0.105410    0.269674    0.914405  14:26     \n",
      "1         0.095276    0.345360    0.906054  14:26     \n",
      "2         0.101761    0.294705    0.911621  14:27     \n",
      "3         0.060816    0.221886    0.932498  14:26     \n",
      "4         0.041902    0.226261    0.931106  14:26     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(5, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))\n",
    "learner.save('aa1/35th_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         0.092591    0.246650    0.924148  14:23     \n",
      "1         0.104496    0.202555    0.938065  14:26     \n",
      "2         0.058693    0.227357    0.932498  14:27     \n",
      "3         0.062887    0.211304    0.934586  14:25     \n",
      "4         0.022956    0.194777    0.942937  14:25     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(5, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))\n",
    "learner.save('aa1/40th_cycle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating prediction\n",
    "Now that the model is trained, we want to generate predictions from the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(df):\n",
    "    text_array = df[\"text\"].tolist()\n",
    "    print(len(text_array))\n",
    "\n",
    "    final_preds = []\n",
    "\n",
    "    for text in text_array:\n",
    "      preds = learner.predict(text)\n",
    "      final_preds.append(str(preds[0]))\n",
    "\n",
    "    targets = df[\"label\"].tolist()\n",
    "\n",
    "    err=[]\n",
    "    count =0;\n",
    "    tst = len(text_array)\n",
    "\n",
    "    for i in range(tst):\n",
    "        if(targets[i]==final_preds[i]):\n",
    "          count = count+1\n",
    "        else:\n",
    "          err.append((targets[i],final_preds[i]))\n",
    "    print(\"Accuracy: \")\n",
    "    print(count/tst)\n",
    "    print(err)\n",
    "\n",
    "    return final_preds,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3592\n",
      "Accuracy: \n",
      "0.9479398663697105\n",
      "[('shunil_gongopaddhay', 'shottojit_roy'), ('shunil_gongopaddhay', 'humayun_ahmed'), ('shomresh', 'MZI'), ('toslima_nasrin', 'manik_bandhopaddhay'), ('shirshendu', 'shunil_gongopaddhay'), ('shordindu', 'robindronath'), ('shottojit_roy', 'MZI'), ('robindronath', 'bongkim'), ('shomresh', 'shirshendu'), ('humayun_ahmed', 'toslima_nasrin'), ('humayun_ahmed', 'MZI'), ('shirshendu', 'shottojit_roy'), ('shordindu', 'nihar_ronjon_gupta'), ('shordindu', 'MZI'), ('bongkim', 'shorotchandra'), ('manik_bandhopaddhay', 'MZI'), ('humayun_ahmed', 'toslima_nasrin'), ('robindronath', 'nazrul'), ('humayun_ahmed', 'MZI'), ('nihar_ronjon_gupta', 'MZI'), ('manik_bandhopaddhay', 'toslima_nasrin'), ('shorotchandra', 'robindronath'), ('tarashonkor', 'nihar_ronjon_gupta'), ('shordindu', 'tarashonkor'), ('nihar_ronjon_gupta', 'shunil_gongopaddhay'), ('nazrul', 'toslima_nasrin'), ('shirshendu', 'shomresh'), ('robindronath', 'shordindu'), ('manik_bandhopaddhay', 'MZI'), ('shomresh', 'humayun_ahmed'), ('toslima_nasrin', 'MZI'), ('nazrul', 'shunil_gongopaddhay'), ('shottojit_roy', 'MZI'), ('shordindu', 'shunil_gongopaddhay'), ('robindronath', 'manik_bandhopaddhay'), ('shorotchandra', 'shordindu'), ('shirshendu', 'shomresh'), ('robindronath', 'humayun_ahmed'), ('robindronath', 'shordindu'), ('shomresh', 'humayun_ahmed'), ('shorotchandra', 'robindronath'), ('shirshendu', 'shottojit_roy'), ('shordindu', 'shunil_gongopaddhay'), ('shirshendu', 'humayun_ahmed'), ('shordindu', 'shunil_gongopaddhay'), ('robindronath', 'bongkim'), ('shottojit_roy', 'shunil_gongopaddhay'), ('shirshendu', 'shomresh'), ('shorotchandra', 'robindronath'), ('shordindu', 'humayun_ahmed'), ('nazrul', 'shunil_gongopaddhay'), ('humayun_ahmed', 'MZI'), ('shorotchandra', 'robindronath'), ('nazrul', 'robindronath'), ('shordindu', 'shottojit_roy'), ('shottojit_roy', 'MZI'), ('shordindu', 'shunil_gongopaddhay'), ('robindronath', 'shordindu'), ('robindronath', 'toslima_nasrin'), ('shordindu', 'bongkim'), ('shorotchandra', 'robindronath'), ('nihar_ronjon_gupta', 'tarashonkor'), ('shirshendu', 'shordindu'), ('shorotchandra', 'robindronath'), ('toslima_nasrin', 'MZI'), ('zahir_rayhan', 'humayun_ahmed'), ('shorotchandra', 'bongkim'), ('shirshendu', 'robindronath'), ('nazrul', 'shunil_gongopaddhay'), ('manik_bandhopaddhay', 'MZI'), ('nazrul', 'robindronath'), ('humayun_ahmed', 'MZI'), ('manik_bandhopaddhay', 'toslima_nasrin'), ('tarashonkor', 'zahir_rayhan'), ('shirshendu', 'shunil_gongopaddhay'), ('robindronath', 'toslima_nasrin'), ('zahir_rayhan', 'shunil_gongopaddhay'), ('MZI', 'toslima_nasrin'), ('nazrul', 'shunil_gongopaddhay'), ('bongkim', 'tarashonkor'), ('shottojit_roy', 'MZI'), ('nazrul', 'robindronath'), ('nihar_ronjon_gupta', 'shottojit_roy'), ('shirshendu', 'shunil_gongopaddhay'), ('shirshendu', 'shunil_gongopaddhay'), ('tarashonkor', 'robindronath'), ('MZI', 'humayun_ahmed'), ('shottojit_roy', 'nihar_ronjon_gupta'), ('shunil_gongopaddhay', 'shottojit_roy'), ('manik_bandhopaddhay', 'shirshendu'), ('manik_bandhopaddhay', 'nihar_ronjon_gupta'), ('shorotchandra', 'nihar_ronjon_gupta'), ('shirshendu', 'shomresh'), ('shottojit_roy', 'MZI'), ('nihar_ronjon_gupta', 'shunil_gongopaddhay'), ('humayun_ahmed', 'shottojit_roy'), ('humayun_ahmed', 'MZI'), ('tarashonkor', 'robindronath'), ('shomresh', 'shunil_gongopaddhay'), ('robindronath', 'MZI'), ('bongkim', 'toslima_nasrin'), ('bongkim', 'robindronath'), ('shottojit_roy', 'humayun_ahmed'), ('tarashonkor', 'shirshendu'), ('tarashonkor', 'shunil_gongopaddhay'), ('shottojit_roy', 'nihar_ronjon_gupta'), ('shirshendu', 'shunil_gongopaddhay'), ('nazrul', 'shunil_gongopaddhay'), ('shirshendu', 'shunil_gongopaddhay'), ('shirshendu', 'shunil_gongopaddhay'), ('nihar_ronjon_gupta', 'humayun_ahmed'), ('robindronath', 'bongkim'), ('humayun_ahmed', 'shunil_gongopaddhay'), ('shorotchandra', 'robindronath'), ('humayun_ahmed', 'MZI'), ('tarashonkor', 'shordindu'), ('shordindu', 'robindronath'), ('shordindu', 'bongkim'), ('tarashonkor', 'nihar_ronjon_gupta'), ('shorotchandra', 'robindronath'), ('shomresh', 'shirshendu'), ('shirshendu', 'shomresh'), ('toslima_nasrin', 'shottojit_roy'), ('MZI', 'toslima_nasrin'), ('humayun_ahmed', 'shunil_gongopaddhay'), ('toslima_nasrin', 'shunil_gongopaddhay'), ('nihar_ronjon_gupta', 'shordindu'), ('robindronath', 'MZI'), ('shirshendu', 'humayun_ahmed'), ('shorotchandra', 'nazrul'), ('shorotchandra', 'robindronath'), ('manik_bandhopaddhay', 'toslima_nasrin'), ('MZI', 'humayun_ahmed'), ('shirshendu', 'shomresh'), ('shirshendu', 'toslima_nasrin'), ('robindronath', 'shordindu'), ('shottojit_roy', 'MZI'), ('shirshendu', 'shunil_gongopaddhay'), ('nihar_ronjon_gupta', 'shottojit_roy'), ('manik_bandhopaddhay', 'humayun_ahmed'), ('shirshendu', 'shunil_gongopaddhay'), ('shottojit_roy', 'MZI'), ('manik_bandhopaddhay', 'shirshendu'), ('shordindu', 'robindronath'), ('shirshendu', 'shomresh'), ('tarashonkor', 'shunil_gongopaddhay'), ('shorotchandra', 'robindronath'), ('nihar_ronjon_gupta', 'MZI'), ('robindronath', 'bongkim'), ('shirshendu', 'MZI'), ('tarashonkor', 'shirshendu'), ('manik_bandhopaddhay', 'shirshendu'), ('robindronath', 'shordindu'), ('shordindu', 'tarashonkor'), ('shirshendu', 'shunil_gongopaddhay'), ('shottojit_roy', 'humayun_ahmed'), ('shordindu', 'bongkim'), ('humayun_ahmed', 'shottojit_roy'), ('shorotchandra', 'robindronath'), ('nihar_ronjon_gupta', 'shomresh'), ('robindronath', 'bongkim'), ('nazrul', 'MZI'), ('nazrul', 'robindronath'), ('tarashonkor', 'shorotchandra'), ('bongkim', 'shorotchandra'), ('shordindu', 'tarashonkor'), ('shomresh', 'humayun_ahmed'), ('nihar_ronjon_gupta', 'shirshendu'), ('shirshendu', 'humayun_ahmed'), ('shirshendu', 'humayun_ahmed'), ('shirshendu', 'shunil_gongopaddhay'), ('shorotchandra', 'bongkim'), ('manik_bandhopaddhay', 'toslima_nasrin'), ('bongkim', 'shorotchandra'), ('MZI', 'toslima_nasrin'), ('manik_bandhopaddhay', 'toslima_nasrin'), ('robindronath', 'shordindu'), ('shirshendu', 'humayun_ahmed'), ('nihar_ronjon_gupta', 'shottojit_roy'), ('zahir_rayhan', 'humayun_ahmed'), ('nihar_ronjon_gupta', 'shomresh'), ('shottojit_roy', 'MZI'), ('nihar_ronjon_gupta', 'MZI'), ('MZI', 'toslima_nasrin'), ('zahir_rayhan', 'manik_bandhopaddhay'), ('robindronath', 'shunil_gongopaddhay'), ('shomresh', 'shunil_gongopaddhay')]\n"
     ]
    }
   ],
   "source": [
    "pred,targ = testing(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this NoteBook, I explain how to combine the ``transformers`` library with the beloved ``fastai`` library. It aims to make you understand where to look and modify both libraries to make them work together. Likely, it allows you to use **Slanted Triangular Learning Rates**, **Discriminate Learning Rate** and even **Gradual Unfreezing**. As a result, without even tunning the parameters, you can obtain rapidly state-of-the-art results.\n",
    "\n",
    "This year, the transformers became an essential tool to NLP. Because of that, I think that pre-trained transformers architectures will be integrated soon to future versions of fastai. Meanwhile, this tutorial is a good starter.\n",
    "\n",
    "I hope you enjoyed this first article and found it useful. \n",
    "Thanks for reading and don't hesitate in leaving questions or suggestions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* Hugging Face, Transformers GitHub (Nov 2019), [https://github.com/huggingface/transformers](https://github.com/huggingface/transformers)\n",
    "* Fast.ai, Fastai documentation (Nov 2019), [https://docs.fast.ai/text.html](https://docs.fast.ai/text.html)\n",
    "* Jeremy Howard & Sebastian Ruder, Universal Language Model Fine-tuning for Text Classification (May 2018), [https://arxiv.org/abs/1801.06146](https://arxiv.org/abs/1801.06146)\n",
    "* Keita Kurita's article : [A Tutorial to Fine-Tuning BERT with Fast AI](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/) (May 2019)\n",
    "* Dev Sharma's article : [Using RoBERTa with Fastai for NLP](https://medium.com/analytics-vidhya/using-roberta-with-fastai-for-nlp-7ed3fed21f6c) (Sep 2019)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
